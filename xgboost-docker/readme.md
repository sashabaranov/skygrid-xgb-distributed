## Распределенный XGBoost

Здесь лежит docker контейнер, запускающий распределенную версию XGboost. Все файлы, кроме `start.sh`,
используются для построения конетйнера. В [start.sh](./start.sh) написан пример запуска обучения на 2-х
машинах. Для обучения использовались данные из 
[otto](https://www.kaggle.com/c/otto-group-product-classification-challenge). В [data](./data) лежат
данные первой машины, причем только первые 1000 строк части тестовой выборки.

### Подготовка и формат данных  

Данные разбиваются на части для каждого из контейнеров. На каждой машине необходимо создать директорию
с частями тестовой выборки и конфигурационным файлом для XGBoost.

#### Формат обучающей выборки

XGBoost для обучающей выборки использует данные формата LibSVM 
([пример](https://github.com/dmlc/xgboost/tree/master/demo/binary_classification#tutorial)).
Прежде всего, необходимо преобразовать обучающую выборку к данному виду. 

Далее необходимо разбить данные. Разбиение производится по столбцам (признакам), можно использовать 
[стандартный скрипт](https://github.com/dmlc/xgboost/blob/master/multi-node/col-split/splitsvm.py)

#### Формат тестовой выборки

Данные для тестирования тоже разбиваются на части, но уже построчно.

#### Подготовка данных

Необходимо для каждой из машин сделать следущее:
* Создать пустую директорию, которая будет в последствии монтироваться в контейнер
* Положить части обучающей выборки и тестовых данных в директорию в соответствующем формате.
* Создать в директории конфирурационный файл для XGBoost с необходимыми параметрами
([пример](https://github.com/dmlc/xgboost/blob/master/multi-node/col-split/mushroom-col.conf))

#### Формат конфигурационного файла XGBoost

Кроме параметров самого алгоритма, в конфигурационном файле должны быть записаны пути к файлам с
обучающей выборкой (data = "...") и тестовыми дынными (test:data = "..."). Так как директория внутри
контейнера будет монтироваться в `/data`, то для .тих параметров следует использовать абсолютные пути,
начинающиеся с `data` ([пример](data/otto.conf)).

### NFS сервер

Для запуска контейнеров необходимо указывать ip и порт nfs-сервера. Для на сервере должна быть доступна
директория `/mirrior`, в которой должен быть установлен XGBoost. Контейнеры будут пытаться монтировать
это директорию командой `mount -t nfs -o proto=tcp,port=$nfs_port $nfs_ip:/mirror /mirror`. Далее, для
файлов модели контейнеры создадут директорию с именем задачи (командой `mkdir /mirror/${task}`).
В последствии обучение контейнеров будет проходить на полученном файле модели с наибольшим номером.
Пример запкованного в docker nfs-сервера лежит [здесь](../multi-node-example/nfs-docker/).

### Etcd сервер

Для запуска контейнеров необходимо указывать ip и порт etcd-сервера (использовалась версия 
[2.0.5](https://github.com/coreos/etcd/releases/tag/v2.0.5)). Для каждой задачи контейнеры создают 
ключи в директории с названием задачи (`http://$etcd_ip:$etcd_port/v2/keys/$task`), после завершения
директория удаляется.

### Запуск контейнеров

Прежде всего, строим все необходимые контейнеры (на каждой машине), например:
```
sudo docker build -t kochetovnicolai/nfs-server ../multi-node-example/nfs-docker
sudo docker build -t kochetovnicolai/multinode-xgboost .
```
Далее, запускаем nfs и etcd сервер (на одной из машин), получаем их ip и порт.

После этого, на каждой машине запускаем контенер с XGBoost. Все кнтейнеры должны завершить свою работу,
после чего в директории с данными должен появиться файл с предсказаниями. [Пример](./start.sh) запуска
в первой строчке получает ip машины, затем запускает контейнер с необходимыми параметрами:

0. `-v path_to_data:/data` - монтируем директорию с данными `path_to_data`
1. `xgboost_config` - имя конфигурационного файла XGBoost в директории с данными
2. `etcd_ip` и `etcd_port` - ip и порт etcd сервера
3. `nfs_ip` и `nfs_port` - ip и порт nfs сервера
4. `host_ip` - ip машины, на которой запускаем контейнер
5. `clients_number` - число запускаемых контейнеров
6. `task` - приозвольный идентификатор задачи
